import { sql } from "@octocoach/db/src";
import { Database } from "@octocoach/db/src/connection";
import { makeCosineDistance } from "@octocoach/db/src/embedding";
import { skills } from "@octocoach/db/src/schema/skills";
import { OpenAIEmbeddings } from "langchain/embeddings/openai";
import {
  ChatPromptTemplate,
  HumanMessagePromptTemplate,
  SystemMessagePromptTemplate,
} from "langchain/prompts";
import { z } from "zod";
import { createFunctionFromZodSchema } from "./helpers";
import { ChatOpenAI } from "langchain/chat_models/openai";
import { JsonKeyOutputFunctionsParser } from "langchain/output_parsers";
import { LLMChain } from "langchain/chains";

const attrName = "skill";

const saveSkill = createFunctionFromZodSchema({
  name: "save_skill",
  description: "save the closest matching skill if it exists",
  attrName,
  zodSchema: z
    .string()
    .optional()
    .describe(
      "The name of the selected skill, `undefined` if the skill was not found in the list"
    ),
});

const embeddingsApi = new OpenAIEmbeddings();

const prompt = ChatPromptTemplate.fromPromptMessages([
  SystemMessagePromptTemplate.fromTemplate(`
    You will be provided with a Skill Descriptor and a list of possible matching skills from a database.
    Use the \`${saveSkill.name}\` function to ${saveSkill.description}.
    Call \`${saveSkill.name}\` with \`undefined\` if the Skill does not appear in the list.
  `),
  HumanMessagePromptTemplate.fromTemplate(`
  Skill: {description}
  Possible Matches:
  {possibleMatches}
  `),
]);

const llm = new ChatOpenAI({
  temperature: 0,
  modelName: "gpt-3.5-turbo-0613",
});

const outputParser = new JsonKeyOutputFunctionsParser({ attrName });

const chain = new LLMChain({
  prompt,
  llm,
  llmKwargs: { functions: [saveSkill] },
  outputParser,
});

export const matchSkill = async ({
  db,
  description,
}: {
  db: Database;
  description: string;
}) => {
  console.log(`Finding matches for ${description}`);
  const distance = await makeCosineDistance(description);

  const order = sql`
  CASE
    WHEN ${skills.descriptionEmbedding} IS NULL
    THEN (${distance(skills.nameEmbedding)})
    ELSE ((${distance(skills.nameEmbedding)}) + (${distance(
    skills.descriptionEmbedding
  )})) / 2
  END`;

  const results = await db.select().from(skills).orderBy(order).limit(7);

  const possibleMatches = results.map(({ name }) => `- ${name}`).join("\n");

  console.log("Possible matches", possibleMatches);

  const { text } = (await chain.call({
    description,
    possibleMatches,
  })) as {
    text: string;
  };

  console.log(`Selected: ${text}`);

  /* ToDo:
   *
   * Instead of selecting only 1 skill from the list and returning undefined, we should call it with an array of matching skills
   * We could also pass in the job title, summary of the tech stack (other outputs generated by the first model)
   * The skills macther will then send back and array of matching skills.
   * We could also ask it  to pass a boolean if the item apprears in the list of not
   * We could also perhaps do some preliminary checks with string comparison and then progressively pass to the LLM.
   * We could also save synonyms in a sort of "cache" for the llm.
   * This way we reduce unnecessary calls to the model.
   * Of course, if we pass in the Task description as context, this macting won't work...
   * Deal with this tomorrow!
   */

  if (!text) return undefined;
  return db.query.skills.findFirst({
    orderBy: order,
  });
};
